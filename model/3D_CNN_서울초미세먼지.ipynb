{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4fcacffb-40d2-4954-b427-47c8d261828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization,Conv3D,Dropout, MaxPooling3D, Flatten, Dense,Concatenate, Reshape, TimeDistributed, Input, concatenate, LSTM,  Conv2D, MaxPooling2D, RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab3eebfa-09ff-4e03-991b-171c38cc8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서울 PM2.5 초미세먼지 데이터 불러오기\n",
    "pm_data = pd.read_csv(\"./daily_seoul_pm25.csv\", header = [0, 1], index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e8fea6-951a-4ae9-8643-6537c7f6657a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>PM25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>지역</th>\n",
       "      <th>서울 서대문구</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>26.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>40.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-05</th>\n",
       "      <td>46.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PM25\n",
       "지역         서울 서대문구\n",
       "2019-01-01    26.6\n",
       "2019-01-02    21.4\n",
       "2019-01-03    23.9\n",
       "2019-01-04    40.1\n",
       "2019-01-05    46.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2571eab9-7173-4212-8a87-23a380a6ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 datetime 형식으로 변환\n",
    "pm_data.index = pd.to_datetime(pm_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea0dffab-2eda-4726-9eca-447be19d7e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021년 01월 01일부터 사용\n",
    "pm_data = pm_data.loc[\"2021-01-01\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb0f8cb3-0bea-4573-be36-7add1faa87d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1e31741-6cd1-4746-83f9-c84a72151c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국내 기상데이터 불러오기\n",
    "climate_data = pd.read_csv(\"C:/Windows/System32/01.Final_project/data/pm25_final.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94d86d39-91fb-47eb-8199-c6960cc64e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 datetime 형식으로 변환\n",
    "climate_data.index = pd.to_datetime(climate_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf5fd443-ccda-4e56-9f1e-26cd0ad19332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('PM25', '강원 강릉시')</th>\n",
       "      <th>('PM25', '광주 북구')</th>\n",
       "      <th>('PM25', '대전 중구')</th>\n",
       "      <th>('PM25', '부산 해운대구')</th>\n",
       "      <th>('PM25', '서울 서대문구')</th>\n",
       "      <th>('강수량', '90')</th>\n",
       "      <th>('강수량', '101')</th>\n",
       "      <th>('강수량', '102')</th>\n",
       "      <th>('강수량', '105')</th>\n",
       "      <th>('강수량', '108')</th>\n",
       "      <th>...</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>15.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 06:00:00</th>\n",
       "      <td>10.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 09:00:00</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 12:00:00</th>\n",
       "      <td>14.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 15:00:00</th>\n",
       "      <td>9.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>15.3</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ('PM25', '강원 강릉시')  ('PM25', '광주 북구')  ('PM25', '대전 중구')  \\\n",
       "2019-01-01 03:00:00                15.0               20.3               39.0   \n",
       "2019-01-01 06:00:00                10.7               22.0               36.0   \n",
       "2019-01-01 09:00:00                14.0               21.7               31.0   \n",
       "2019-01-01 12:00:00                14.0               18.3               29.0   \n",
       "2019-01-01 15:00:00                 9.5               15.3               17.7   \n",
       "\n",
       "                     ('PM25', '부산 해운대구')  ('PM25', '서울 서대문구')  ('강수량', '90')  \\\n",
       "2019-01-01 03:00:00                 19.3                 33.7            0.0   \n",
       "2019-01-01 06:00:00                 19.7                 32.0            0.0   \n",
       "2019-01-01 09:00:00                 22.0                 29.3            0.0   \n",
       "2019-01-01 12:00:00                 17.0                 22.7            0.0   \n",
       "2019-01-01 15:00:00                 15.3                 27.3            0.0   \n",
       "\n",
       "                     ('강수량', '101')  ('강수량', '102')  ('강수량', '105')  \\\n",
       "2019-01-01 03:00:00             0.0             0.0             0.0   \n",
       "2019-01-01 06:00:00             0.0             0.0             0.0   \n",
       "2019-01-01 09:00:00             0.0             0.0             0.0   \n",
       "2019-01-01 12:00:00             0.0             0.0             0.0   \n",
       "2019-01-01 15:00:00             0.0             0.0             0.0   \n",
       "\n",
       "                     ('강수량', '108')  ...  month_11  month_12  hour_0  hour_3  \\\n",
       "2019-01-01 03:00:00             0.0  ...     False     False   False    True   \n",
       "2019-01-01 06:00:00             0.0  ...     False     False   False   False   \n",
       "2019-01-01 09:00:00             0.0  ...     False     False   False   False   \n",
       "2019-01-01 12:00:00             0.0  ...     False     False   False   False   \n",
       "2019-01-01 15:00:00             0.0  ...     False     False   False   False   \n",
       "\n",
       "                     hour_6  hour_9  hour_12  hour_15  hour_18  hour_21  \n",
       "2019-01-01 03:00:00   False   False    False    False    False    False  \n",
       "2019-01-01 06:00:00    True   False    False    False    False    False  \n",
       "2019-01-01 09:00:00   False    True    False    False    False    False  \n",
       "2019-01-01 12:00:00   False   False     True    False    False    False  \n",
       "2019-01-01 15:00:00   False   False    False     True    False    False  \n",
       "\n",
       "[5 rows x 2225 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ac4f1dd-583d-41c8-8db2-fd4e624500c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15727, 2225)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bced259-1b2a-4d7f-a4a9-333272acf7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속변수들은 제거\n",
    "climate_data = climate_data.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a133a8d6-6d3b-45d8-84a5-71bc86780d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜별로 평균내서 그룹화하기\n",
    "grouped_climate = climate_data.groupby(climate_data.index.date)\n",
    "grouped_climate = grouped_climate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a56abb9-211b-4673-921e-4f313ca2d57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1966, 2220)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_climate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab107700-514f-42f6-9df0-6df8ab5efc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 datetime 형식으로 변환\n",
    "grouped_climate.index = pd.to_datetime(grouped_climate.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5855acc1-a153-42c1-aced-d73c128c254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2021년 01월 01일부터 추출\n",
    "grouped_climate = grouped_climate.loc[\"2021-01-01\":,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2de56ae9-bf1f-40cf-b186-16790ec3f455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 2220)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_climate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c2e3071d-c14c-4d66-b329-614d986c1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에어로졸 이미지 불러오기\n",
    "img_df = pd.read_csv(r\"C:\\Windows\\System32\\01.Final_project\\jayden\\final_aerosol_df.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b192f889-a652-4759-8419-72bc2a02074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 datetime 형식으로 변환\n",
    "img_df.index = pd.to_datetime(img_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a01cbf30-c74b-4216-b50c-ef745567e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상,미세먼지 데이터와 동일하게 2024-05-19 까지만 추출\n",
    "img_df = img_df.loc[:\"2024-05-19 02:45:00\",:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad20cabf-f2b5-46fa-9a44-2a40491b1d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3699, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb1eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3699 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "62783660-5f06-4d63-98d3-7b6524d36b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                DateTime\n",
      "0    2021-01-01 00:45:00\n",
      "1    2021-01-01 01:45:00\n",
      "2    2021-01-01 02:45:00\n",
      "3    2021-01-02 00:45:00\n",
      "4    2021-01-02 01:45:00\n",
      "...                  ...\n",
      "3700 2024-05-18 01:45:00\n",
      "3701 2024-05-18 02:45:00\n",
      "3702 2024-05-19 00:45:00\n",
      "3703 2024-05-19 01:45:00\n",
      "3704 2024-05-19 02:45:00\n",
      "\n",
      "[3705 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 에어로졸 이미지 중, 특정한 날짜 2개에 결측치가 있는 것으로 보임. 어느 날짜가 결측인지 확인하기위해 모든 날짜를 생성해서 비교해보기.\n",
    "\n",
    "# 2021년01월01일 00:45:00 부터 2024년 5월19일 02:25:00 까지 생성\n",
    "date_range = pd.date_range(start=\"2021-01-01 00:45:00\", end=\"2024-05-19 02:45:00\", freq='D')\n",
    "\n",
    "# 각 날짜에 대해 세 개의 시간대를 포함하는 리스트를 생성\n",
    "date_series = pd.Series(\n",
    "    pd.date_range(start=\"2021-01-01 00:45:00\", end=\"2024-05-19 02:45:00\", freq='D').strftime('%Y-%m-%d')\n",
    ").apply(lambda date: [f\"{date} 00:45:00\", f\"{date} 01:45:00\", f\"{date} 02:45:00\"])\n",
    "\n",
    "# explode 메소드를 사용하여 각 날짜별 시간 리스트를 평탄화하여 단일 시리즈로 변환 후 인덱스는 drop\n",
    "flat_series = date_series.explode().reset_index(drop=True)\n",
    "\n",
    "# pd.to_datetime 함수를 사용하여 평탄화된 문자열 시리즈를 datetime 형식으로 변환\n",
    "datetime_series = pd.to_datetime(flat_series)\n",
    "\n",
    "# 변환된 datetime 시리즈를 데이터프레임으로 생성\n",
    "datetime_df = pd.DataFrame(datetime_series, columns=[\"DateTime\"])\n",
    "print(datetime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "46bb5dec-b222-44a5-bef9-8339022d7902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 날짜에 에어로졸 이미지 df 머지하기\n",
    "merged_df = datetime_df.merge(img_df, left_on=\"DateTime\", right_index=True, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "66a0aa51-09d3-4bb1-9928-3d23d7545585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3705, 2)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd23c435-e0dc-4f5e-ba7e-5da1943d08c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>2021-05-10 00:45:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2021-05-10 01:45:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2021-05-10 02:45:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>2022-07-29 00:45:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>2022-07-29 01:45:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>2022-07-29 02:45:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DateTime File\n",
       "387  2021-05-10 00:45:00  NaN\n",
       "388  2021-05-10 01:45:00  NaN\n",
       "389  2021-05-10 02:45:00  NaN\n",
       "1722 2022-07-29 00:45:00  NaN\n",
       "1723 2022-07-29 01:45:00  NaN\n",
       "1724 2022-07-29 02:45:00  NaN"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 에어로졸 이미지 결측인 부분\n",
    "merged_df[merged_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29c4c5d3-d54b-4c16-88f9-8864bf911fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ddbdc57-cf94-463b-8126-9dc867300397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미세먼지 데이터에서 이미지가 결측인 날짜 제거\n",
    "pm_data = pm_data.drop(\"2021-05-10\", axis = 0)\n",
    "pm_data = pm_data.drop(\"2022-07-29\", axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cbc8ad66-a19f-48a7-8bf9-001d6e08111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상 데이터에서 이미지가 결측인 날짜 제거\n",
    "grouped_climate = grouped_climate.drop(\"2021-05-10\", axis = 0)\n",
    "grouped_climate = grouped_climate.drop(\"2022-07-29\", axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc6eee08-0063-4044-bca0-535ea3d520c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1233, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bb2e944a-c249-4a08-8084-c0427dc117c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1233.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df.shape[0] / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "420eb9e0-9d8c-4e1d-a66e-9e0089046603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1233, 2220)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_climate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "111d3c70-57b6-4df5-a043-b1de15584faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "839\n",
      "1227\n"
     ]
    }
   ],
   "source": [
    "# 보간적용한 사진 몇 번째 인덱스인지 확인하기\n",
    "print(img_df.index.get_loc(\"2021-01-26 00:45:00\"))\n",
    "# 보간적용한 사진 몇 번째 인덱스인지 확인하기\n",
    "print(img_df.index.get_loc(\"2021-10-08 02:45:00\"))\n",
    "# 보간적용한 사진 몇 번째 인덱스인지 확인하기\n",
    "print(img_df.index.get_loc(\"2022-02-15 00:45:00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "410954e0-2e94-40e6-bc2f-c5c079863897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스 추출해두기\n",
    "idx = pm_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1a2c4cab-f2f7-40b9-b986-5a9f037bb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에어로졸 이미지 불러오기 및 전처리 함수\n",
    "def preprocess_image(img_df, no_crop_dates_indice, base_path): # 이미지데이터프레임, 전처리안할 이미지 인덱스번호, 이미지 경로 설정\n",
    "    img_vectors = {\n",
    "        '0045': [], # 00시 45분 이미지 벡터를 담을 리스트\n",
    "        '0145': [], # 01시 45분 이미지 벡터를 담을 리스트\n",
    "        '0245': [] # 02시 45분 이미지 벡터를 담을 리스트\n",
    "    }\n",
    "\n",
    "    for i in range(len(img_df)):\n",
    "        date = img_df.index[i]\n",
    "        img_filename = img_df.iloc[i, 0][56:]  # 사용한 컴퓨터가 여러대여서 경로가 다 다르기때문에, 이미지파일명만 추출.\n",
    "        img_path = os.path.join(base_path, img_filename) # 함수 호출 할때, 본인 컴퓨터내 에어로졸 이미지 경로는 base_path 자리에 설정.\n",
    "        img = cv2.imread(img_path) # open cv 사용\n",
    "\n",
    "        if img is not None:  # 이미지 로드가 성공했는지 확인\n",
    "            if i not in no_crop_dates_indice:  # 인덱스가 no_crop_dates_indice에 있는지 확인\n",
    "                img = img[150:1100, :]  # 위 아래 필요없는 정보 자르기\n",
    "                img = img[:, 200:-200]  # 왼쪽 오른쪽 필요없는 정보 자르기\n",
    "                img = img[400:1000, :]  # 추가 잘라내기 (필요시)\n",
    "\n",
    "                # 이미지가 비어 있지 않은지 확인\n",
    "                if img.size == 0: \n",
    "                    print(f\"현재 {img_path} 이미지는 비어있습니다\") # 만약 위의 크롭을 거치고 사이즈가 0이된 이미지가있는지 확인\n",
    "                    continue # 0이 된게 있다면 스킵하기\n",
    "\n",
    "            img = cv2.resize(img, (128, 128))  # 이미지 크기를 일관되게 조정\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR을 RGB로 변환\n",
    "            img = img / 255.0  # 정규화 (0~1 범위로 변경하기)\n",
    "\n",
    "            time_key = date.strftime('%H%M') # date (인덱스) 에서 시간과 분만 추출\n",
    "            if time_key in img_vectors:\n",
    "                img_vectors[time_key].append(img) # 각 이미지가 00:45인지 01:45인지 02:45인지 확인 후, 알맞는 리스트로 append\n",
    "\n",
    "    return img_vectors\n",
    "\n",
    "\n",
    "# 크기 조정 제외할 이미지들의 인덱스 (날짜) 이미 보간법 적용된 사진들.\n",
    "no_crop_dates_indice = [72, 836, 1224] # 72번, 836번, 1224번 사진은 crop 전처리 거치지않기.\n",
    "\n",
    "# 이미지 파일 경로\n",
    "base_path = \"C:/Users/user/Desktop/koreaIT/aerosol_image/new_images2/\"  # 현재 컴퓨터내 이미지폴더 디렉토리\n",
    "\n",
    "# 이미지 벡터화\n",
    "img_vectors = preprocess_image(img_df, no_crop_dates_indice, base_path) # 함수 호출\n",
    "\n",
    "# 데이터프레임 생성\n",
    "result_df = pd.DataFrame({\n",
    "    \"index\" : idx, # 추출해둔 인덱스로 date 생성\n",
    "    '0045': img_vectors['0045'],\n",
    "    '0145': img_vectors['0145'],\n",
    "    '0245': img_vectors['0245']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b0eb0e57-799a-48da-ac3e-6f06b0cf25fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1233, 4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "23995ff5-3386-403b-b52e-7e56553874ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 이미지 벡터 df의 인덱스를 datetime 형식으로 변경\n",
    "result_df = result_df.set_index(\"index\")\n",
    "result_df.index = pd.to_datetime(result_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a09f29-8cc9-4d36-8113-c670958b5c7b",
   "metadata": {},
   "source": [
    "## 시퀀스 윈도우 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0f08061a-0da0-400a-b781-e8f93e7be8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상데이터, 미세먼지데이터, 에어로졸 이미지데이터를 한번에 시퀀스 데이터로 변환해주는 함수\n",
    "def create_combined_sliding_window(climate_data, pm_data, aod_df, past_days=3, future_days=3):\n",
    "    x_climate, x_aod_0045, x_aod_0145, x_aod_0245, y = [], [], [], [], []\n",
    "    \n",
    "    for i in range(len(climate_data) - past_days - future_days + 1):\n",
    "        # 과거 'past_days' 일의 기상 데이터\n",
    "        climate_window = climate_data[i:i+past_days]\n",
    "        # 미래 'future_days' 일의 미세먼지 데이터\n",
    "        pm_window = pm_data[i+past_days:i+past_days+future_days]\n",
    "        \n",
    "        # 에어로졸 이미지의 슬라이딩 윈도우\n",
    "        aod_window_0045 = aod_df['0045'].iloc[i:i + past_days]\n",
    "        aod_window_0145 = aod_df['0145'].iloc[i:i + past_days]\n",
    "        aod_window_0245 = aod_df['0245'].iloc[i:i + past_days]\n",
    "\n",
    "        # 결측치가 없는 경우에만 추가\n",
    "        if not (pd.DataFrame(climate_window).isna().any().any() or\n",
    "                pd.DataFrame(pm_window).isna().any().any() or\n",
    "                aod_window_0045.isnull().any() or\n",
    "                aod_window_0145.isnull().any() or\n",
    "                aod_window_0245.isnull().any()):\n",
    "            \n",
    "            x_climate.append(climate_window)\n",
    "            x_aod_0045.append(np.stack(aod_window_0045.values))\n",
    "            x_aod_0145.append(np.stack(aod_window_0145.values))\n",
    "            x_aod_0245.append(np.stack(aod_window_0245.values))\n",
    "            y.append(pm_window)\n",
    "\n",
    "    return (np.array(x_climate),\n",
    "            np.array(x_aod_0045),\n",
    "            np.array(x_aod_0145),\n",
    "            np.array(x_aod_0245),\n",
    "            np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc338062-62c0-4408-9469-9e7b99505e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "x_climate, x_0045, x_0145, x_0245, y_pm = create_combined_sliding_window(grouped_climate, pm_data, result_df, past_days=6, future_days=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c182bbb-2457-410c-b7ff-92905796dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shapes: (772, 6, 2220), (772, 6, 128, 128, 3),(772, 6, 128, 128, 3),(772, 6, 128, 128, 3), (772, 3, 1)\n",
      "validation shapes: (194, 6, 2220), (194, 6, 128, 128, 3),(194, 6, 128, 128, 3),(194, 6, 128, 128, 3), (194, 3, 1)\n",
      "test shapes: (242, 6, 2220), (242, 6, 128, 128, 3),(242, 6, 128, 128, 3),(242, 6, 128, 128, 3), (242, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할 (훈련, 검증, 테스트셋)\n",
    "x_climate_train, x_climate_test,  x_0045_train,  x_0045_test, x_0145_train, x_0145_test, x_0245_train, x_0245_test, y_train, y_test = train_test_split(x_climate, x_0045, x_0145, x_0245, y_pm, test_size=0.2, random_state=42)\n",
    "x_climate_train, x_climate_val, x_0045_train,  x_0045_val, x_0145_train, x_0145_val, x_0245_train, x_0245_val, y_train, y_val = train_test_split(x_climate_train, x_0045_train, x_0145_train, x_0245_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'train shapes: {x_climate_train.shape}, {x_0045_train.shape},{x_0145_train.shape},{x_0245_train.shape}, {y_train.shape}')\n",
    "print(f'validation shapes: {x_climate_val.shape}, {x_0045_val.shape},{x_0145_val.shape},{x_0245_val.shape}, {y_val.shape}')\n",
    "print(f'test shapes: {x_climate_test.shape}, {x_0045_test.shape},{x_0145_test.shape},{x_0245_test.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0be80bac-bfad-47de-91ab-689621915071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상 데이터 스케일링\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "72e50ada-f50c-4807-83b2-9ef5fcd09276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3차원을 스케일링할 수 없기 때문에, 2차원으로 변환 후 다시 3차원으로 재변환\n",
    "climate_train_reshaped = x_climate_train.reshape(x_climate_train.shape[0], -1)\n",
    "climate_val_reshaped = x_climate_val.reshape(x_climate_val.shape[0], -1)\n",
    "climate_test_reshaped = x_climate_test.reshape(x_climate_test.shape[0], -1)\n",
    "\n",
    "climate_train_scaled_reshaped = ss.fit_transform(climate_train_reshaped)\n",
    "climate_val_scaled_reshaped = ss.transform(climate_val_reshaped)\n",
    "climate_test_scaled_reshaped = ss.transform(climate_test_reshaped)\n",
    "\n",
    "scaled_climate_train = climate_train_scaled_reshaped.reshape(x_climate_train.shape)\n",
    "scaled_climate_val = climate_val_scaled_reshaped.reshape(x_climate_val.shape)\n",
    "scaled_climate_test = climate_test_scaled_reshaped.reshape(x_climate_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a9c5853-7763-4b1e-bb85-f53d30e2f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D CNN 정의\n",
    "input_aerosol_0045 = Input(shape=(6, 128, 128, 3))\n",
    "input_aerosol_0145 = Input(shape=(6, 128, 128, 3))\n",
    "input_aerosol_0245 = Input(shape=(6, 128, 128, 3))\n",
    "\n",
    "def create_cnn(input_layer):\n",
    "    x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling3D((1, 2, 2))(x) # 2, 2, 2 넣었더니 에러떠서 공간적 특징을 줄여서 1, 2 ,2로 설정.\n",
    "    x = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling3D((1, 2, 2))(x)\n",
    "    x = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling3D((1, 2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    return x\n",
    "\n",
    "cnn_0045 = create_cnn(input_aerosol_0045)\n",
    "cnn_0145 = create_cnn(input_aerosol_0145)\n",
    "cnn_0245 = create_cnn(input_aerosol_0245)\n",
    "\n",
    "# 기상 데이터 입력\n",
    "input_weather = Input(shape=(6, scaled_climate_train.shape[2])) # 3, 2200이 들어감\n",
    "weather_lstm = LSTM(128, activation='relu', return_sequences=False)(input_weather)\n",
    "\n",
    "# 결합\n",
    "combined = concatenate([cnn_0045, cnn_0145, cnn_0245, weather_lstm])\n",
    "x = Dense(256, activation='relu')(combined)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(3, activation='linear')(x)  # 미래 3일 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "16690497-5929-4db5-8796-da1d688aed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "model = Model(inputs=[input_aerosol_0045, input_aerosol_0145, input_aerosol_0245, input_weather], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"./best_3D_CNN_model_pm25_seoul.h5\", save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "38898f18-7737-4738-ba98-de223f956b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 6, 128, 128, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 6, 128, 128, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 6, 128, 128, 3)]     0         []                            \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)             (None, 6, 128, 128, 32)      2624      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)           (None, 6, 128, 128, 32)      2624      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)           (None, 6, 128, 128, 32)      2624      ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3  (None, 6, 64, 64, 32)        0         ['conv3d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling3d_3 (MaxPoolin  (None, 6, 64, 64, 32)        0         ['conv3d_3[0][0]']            \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_6 (MaxPoolin  (None, 6, 64, 64, 32)        0         ['conv3d_6[0][0]']            \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)           (None, 6, 64, 64, 64)        55360     ['max_pooling3d[0][0]']       \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)           (None, 6, 64, 64, 64)        55360     ['max_pooling3d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)           (None, 6, 64, 64, 64)        55360     ['max_pooling3d_6[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPoolin  (None, 6, 32, 32, 64)        0         ['conv3d_1[0][0]']            \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_4 (MaxPoolin  (None, 6, 32, 32, 64)        0         ['conv3d_4[0][0]']            \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_7 (MaxPoolin  (None, 6, 32, 32, 64)        0         ['conv3d_7[0][0]']            \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)           (None, 6, 32, 32, 128)       221312    ['max_pooling3d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)           (None, 6, 32, 32, 128)       221312    ['max_pooling3d_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)           (None, 6, 32, 32, 128)       221312    ['max_pooling3d_7[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPoolin  (None, 6, 16, 16, 128)       0         ['conv3d_2[0][0]']            \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_5 (MaxPoolin  (None, 6, 16, 16, 128)       0         ['conv3d_5[0][0]']            \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling3d_8 (MaxPoolin  (None, 6, 16, 16, 128)       0         ['conv3d_8[0][0]']            \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 6, 2220)]            0         []                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 196608)               0         ['max_pooling3d_2[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 196608)               0         ['max_pooling3d_5[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 196608)               0         ['max_pooling3d_8[0][0]']     \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 128)                  1202688   ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 589952)               0         ['flatten[0][0]',             \n",
      "                                                                     'flatten_1[0][0]',           \n",
      "                                                                     'flatten_2[0][0]',           \n",
      "                                                                     'lstm[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  1510279   ['concatenate[0][0]']         \n",
      "                                                          68                                      \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 3)                    387       ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 153101827 (584.04 MB)\n",
      "Trainable params: 153101827 (584.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f6cc8aaa-2b23-4e2a-b310-b9d0d1c700a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - ETA: 0s - loss: 786.4438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\koreait\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 250s 10s/step - loss: 786.4438 - val_loss: 227.1125\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 246s 10s/step - loss: 137.0092 - val_loss: 178.2099\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 246s 10s/step - loss: 98.5449 - val_loss: 154.4013\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 246s 10s/step - loss: 69.9230 - val_loss: 119.3560\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 245s 10s/step - loss: 54.4338 - val_loss: 111.1721\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 244s 10s/step - loss: 37.9744 - val_loss: 95.5284\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 244s 10s/step - loss: 27.1015 - val_loss: 98.7946\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 245s 10s/step - loss: 20.4134 - val_loss: 86.5007\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 244s 10s/step - loss: 14.8005 - val_loss: 96.2396\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 245s 10s/step - loss: 12.1968 - val_loss: 89.0454\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit([x_0045_train, x_0145_train, x_0245_train, scaled_climate_train], y_train, epochs=20, batch_size=32,\n",
    "                    validation_data=([x_0045_val, x_0145_val, x_0245_val, scaled_climate_val], y_val), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "94bee105-f10c-408e-bb0e-a29747d8ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 734ms/step - loss: 62.3636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62.3636360168457"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트셋 MSE 추출\n",
    "test_loss = model.evaluate([x_0045_test, x_0145_test, x_0245_test, scaled_climate_test], y_test)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5255bd24-f430-448c-8331-2bc3b0581c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 6s 771ms/step\n",
      "예측값: \n",
      " [[16.588125 24.481993 34.441895]\n",
      " [16.734673 16.685986 27.528059]\n",
      " [11.390153 22.936243 25.380701]]\n",
      "실제값: \n",
      " [[[12.3]\n",
      "  [24.7]\n",
      "  [38.2]]\n",
      "\n",
      " [[12.4]\n",
      "  [15.1]\n",
      "  [21. ]]\n",
      "\n",
      " [[ 8.6]\n",
      "  [11.5]\n",
      "  [30.2]]]\n"
     ]
    }
   ],
   "source": [
    "# 예측 \n",
    "y_pred = model.predict([x_0045_test, x_0145_test, x_0245_test, scaled_climate_test])\n",
    "\n",
    "# 예측 결과 확인\n",
    "print(f'예측값: \\n {y_pred[:3]}')\n",
    "print(f'실제값: \\n {y_test[:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4d295-7d2a-445e-8127-8ab5aaa0318f",
   "metadata": {},
   "source": [
    "## CNN 제외하고 LSTM으로만 돌려보기 (이미지 제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "aea85e3e-5221-4a3f-8450-4f4bc6d42957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 제외했기때문에, 기상, 미세먼지 슬라이딩 윈도우 생성 함수 사용\n",
    "# 기상, 미세먼지 슬라이딩 윈도우 생성 함수\n",
    "def create_sliding_window(climate_data, pm_data, past_days=6, future_days=3):\n",
    "    x_climate, y = [], []\n",
    "    for i in range(len(climate_data) - past_days - future_days + 1):\n",
    "        # 과거 'past_days' 일의 기상 데이터\n",
    "        climate_window = climate_data[i:i+past_days]\n",
    "        # 미래 'future_days' 일의 미세먼지 데이터\n",
    "        pm_window = pm_data[i+past_days:i+past_days+future_days]\n",
    "\n",
    "        # 결측치가 없는 경우에만 추가\n",
    "        if not (pd.DataFrame(climate_window).isna().any().any() or pd.DataFrame(pm_window).isna().any().any()):\n",
    "            x_climate.append(climate_window)\n",
    "            y.append(pm_window)\n",
    "\n",
    "    return np.array(x_climate), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8322e3ca-ab15-4bf2-831e-3beba87c1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 사용하여 시퀀스 데이터 생성\n",
    "xx_climate, yy = create_sliding_window(grouped_climate, pm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b84b3008-ae5d-4518-b547-14e76401f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1208, 6, 2220)\n",
      "(1208, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xx_climate.shape)\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ac2154b1-ed5f-4f51-8778-edce4c8bb692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shapes: (772, 6, 2220), (772, 3, 1)\n",
      "validation shapes: (194, 6, 2220), (194, 3, 1)\n",
      "test shapes: (242, 6, 2220), (242, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할 (훈련, 검증, 테스트셋)\n",
    "xx_climate_train, xx_climate_test, yy_train, yy_test = train_test_split(xx_climate, yy, test_size=0.2, random_state=42)\n",
    "xx_climate_train, xx_climate_val, yy_train, yy_val = train_test_split(xx_climate_train, yy_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'train shapes: {xx_climate_train.shape}, {yy_train.shape}')\n",
    "print(f'validation shapes: {xx_climate_val.shape}, {yy_val.shape}')\n",
    "print(f'test shapes: {xx_climate_test.shape}, {yy_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e04063b1-e17c-49be-b2d5-9e83031cb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9f0c813d-1418-4098-be8c-14688ed17e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상데이터 스케일링\n",
    "xx_climate_train_reshaped = xx_climate_train.reshape(xx_climate_train.shape[0], -1)\n",
    "xx_climate_val_reshaped = xx_climate_val.reshape(xx_climate_val.shape[0], -1)\n",
    "xx_climate_test_reshaped = xx_climate_test.reshape(xx_climate_test.shape[0], -1)\n",
    "\n",
    "xx_climate_train_scaled_reshaped = ss.fit_transform(xx_climate_train_reshaped)\n",
    "xx_climate_val_scaled_reshaped = ss.transform(xx_climate_val_reshaped)\n",
    "xx_climate_test_scaled_reshaped = ss.transform(xx_climate_test_reshaped)\n",
    "\n",
    "xx_scaled_climate_train = xx_climate_train_scaled_reshaped.reshape(xx_climate_train.shape)\n",
    "xx_scaled_climate_val = xx_climate_val_scaled_reshaped.reshape(xx_climate_val.shape)\n",
    "xx_scaled_climate_test = xx_climate_test_scaled_reshaped.reshape(xx_climate_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "01694cff-8c03-4c08-84c1-7b85bd749b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 6, 2220)]         0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 6, 128)            1202688   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 6, 128)            512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6, 128)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 6, 128)            131584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 6, 128)            512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 6, 128)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1533699 (5.85 MB)\n",
      "Trainable params: 1532931 (5.85 MB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 기상 데이터 입력\n",
    "input_weather = Input(shape=(6, 2220))\n",
    "\n",
    "# 첫 번째 LSTM 층\n",
    "x = LSTM(128, activation='relu', return_sequences=True)(input_weather)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# 두 번째 LSTM 층\n",
    "x = LSTM(128, activation='relu', return_sequences=True)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# 세 번째 LSTM 층\n",
    "x = LSTM(128, activation='relu', return_sequences=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Fully Connected (FC) 층\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(3, activation='linear')(x)  # 미래 3일 예측\n",
    "\n",
    "# 모델 생성 및 컴파일\n",
    "lstm_model = Model(inputs=input_weather, outputs=output)\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 모델 요약\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ee1b4651-e68c-4155-a0f0-5067717f92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정 (모델 체크포인트, 조기 종료 등)\n",
    "checkpoint_cb = ModelCheckpoint(\"./best_LSTM_model_pm25.h5\", save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=8, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "220f17d7-330f-46dd-a964-51b4c1c59ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 3s 39ms/step - loss: 333.4209 - val_loss: 318.2815\n",
      "Epoch 2/100\n",
      " 5/25 [=====>........................] - ETA: 0s - loss: 137.6793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\koreait\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 33ms/step - loss: 131.0260 - val_loss: 270.0684\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 122.9194 - val_loss: 254.9355\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 119.9169 - val_loss: 227.6671\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 108.6551 - val_loss: 194.3611\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 32ms/step - loss: 98.1357 - val_loss: 183.8728\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 33ms/step - loss: 100.0663 - val_loss: 162.9826\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 91.2032 - val_loss: 164.0196\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 96.3506 - val_loss: 215.9353\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 81.7825 - val_loss: 301.1610\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 82.2612 - val_loss: 204.0793\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 78.8711 - val_loss: 249.6030\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 79.0200 - val_loss: 220.8650\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 72.5874 - val_loss: 212.9124\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 73.9667 - val_loss: 287.2412\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history = lstm_model.fit(xx_scaled_climate_train, yy_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(xx_scaled_climate_val, yy_val), \n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c9245836-5e76-466d-b79a-0694393e448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 146.6371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "146.63706970214844"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss = lstm_model.evaluate([xx_scaled_climate_test], yy_test)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733272f0-7626-4418-b124-c55f3af6a10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
